# services/layout_analysis_service_paged.py (ë™ì‹œì„± ë¬¸ì œ í•´ê²°)
"""
í˜ì´ì§€ë³„ ì§„í–‰ë¥  ì¶”ì ì´ ê°€ëŠ¥í•œ ë ˆì´ì•„ì›ƒ ë¶„ì„ ì„œë¹„ìŠ¤ (ë™ì‹œ ì‚¬ìš©ì ì§€ì›)
ê° ìŠ¤ë ˆë“œë§ˆë‹¤ ë³„ë„ì˜ PPStructureV3 ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì‹œì„± ë¬¸ì œ í•´ê²°
"""

import json
import time
import logging
from pathlib import Path
from typing import Any, Dict, List, Optional
from dataclasses import dataclass
import traceback
import tempfile
import shutil
import threading

try:
    import fitz  # PyMuPDF for PDF page extraction
    PYMUPDF_AVAILABLE = True
except ImportError:
    fitz = None
    PYMUPDF_AVAILABLE = False
    print("Warning: PyMuPDF not installed. Install with: pip install PyMuPDF")


@dataclass
class LayoutAnalysisResult:
    """ë ˆì´ì•„ì›ƒ ë¶„ì„ ê²°ê³¼"""
    success: bool
    pages: List[Dict[str, Any]]
    markdown_files: List[str]
    confidence: float
    processing_time: float
    output_dir: str
    metadata: Optional[Dict[str, Any]] = None
    error: Optional[str] = None


class LayoutAnalysisServicePaged:
    """
    í˜ì´ì§€ë³„ ì§„í–‰ë¥  ì¶”ì ì´ ê°€ëŠ¥í•œ ë ˆì´ì•„ì›ƒ ë¶„ì„ ì„œë¹„ìŠ¤ (ë©€í‹° ìŠ¤ë ˆë“œ ì•ˆì „)
    ê° ìŠ¤ë ˆë“œë§ˆë‹¤ ë…ë¦½ì ì¸ PaddleOCR ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        
        # ê¸°ë³¸ ì„¤ì •
        self.use_gpu = self.config.get('use_gpu', False)
        self.use_table = self.config.get('use_table', True)
        
        # ìŠ¤ë ˆë“œë³„ ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ (ê° ìŠ¤ë ˆë“œë§ˆë‹¤ ë³„ë„ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤)
        self._local = threading.local()
        
        # ì „ì—­ ëª¨ë¸ ë¡œë“œ ì¹´ìš´í„° (ë””ë²„ê¹…ìš©)
        self._model_load_count = 0
        self._lock = threading.Lock()
        
    def _get_pipeline(self, progress_callback=None):
        """ìŠ¤ë ˆë“œë³„ PP-Structure íŒŒì´í”„ë¼ì¸ íšë“"""
        
        # í˜„ì¬ ìŠ¤ë ˆë“œì— íŒŒì´í”„ë¼ì¸ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ ìƒì„±
        if not hasattr(self._local, 'pipeline') or self._local.pipeline is None:
            try:
                from paddleocr import PPStructureV3
                
                # ìŠ¤ë ˆë“œ ì •ë³´
                thread_id = threading.current_thread().ident
                thread_name = threading.current_thread().name
                
                with self._lock:
                    self._model_load_count += 1
                    current_count = self._model_load_count
                
                print(f"\n{'='*60}")
                print(f"ğŸ”„ ìŠ¤ë ˆë“œë³„ PPStructureV3 ëª¨ë¸ ë¡œë“œ")
                print(f"   ìŠ¤ë ˆë“œ ID: {thread_id}")
                print(f"   ìŠ¤ë ˆë“œ ì´ë¦„: {thread_name}")
                print(f"   ë¡œë“œ ìˆœì„œ: {current_count}ë²ˆì§¸")
                print(f"{'='*60}")
                
                if progress_callback:
                    progress_callback(0, 100, f"ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì¤‘... (ìŠ¤ë ˆë“œ {current_count})")
                
                start_load = time.time()
                
                # ìŠ¤ë ˆë“œë³„ ë…ë¦½ì ì¸ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                self._local.pipeline = PPStructureV3(
                    device='cpu',  # CPU ì‚¬ìš©ìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´
                    use_table_recognition=self.use_table,
                    use_doc_unwarping=False,  # UVDoc ë¹„í™œì„±í™”
                    use_doc_orientation_classify=False  # ë°©í–¥ ë¶„ë¥˜ ë¹„í™œì„±í™”
                )
                
                load_time = time.time() - start_load
                
                print(f"âœ… ìŠ¤ë ˆë“œ {thread_id}: ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
                print(f"   ì†Œìš”ì‹œê°„: {load_time:.2f}ì´ˆ")
                print(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©: ë…ë¦½ ì¸ìŠ¤í„´ìŠ¤")
                print(f"{'='*60}\n")
                
                if progress_callback:
                    progress_callback(100, 100, "ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                        
            except Exception as e:
                print(f"âŒ ìŠ¤ë ˆë“œ {thread_id}: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                raise RuntimeError(f"PPStructureV3 ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                
        return self._local.pipeline
    
    def analyze_document(self, pdf_path: str, output_dir: str = None, 
                        progress_callback=None) -> LayoutAnalysisResult:
        """
        PDF ë¬¸ì„œë¥¼ í˜ì´ì§€ë³„ë¡œ ë¶„ì„ (ìŠ¤ë ˆë“œ ì•ˆì „)
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            progress_callback: ì§„í–‰ë¥  ì½œë°± (current, total, message)
        """
        if not PYMUPDF_AVAILABLE:
            return LayoutAnalysisResult(
                success=False,
                pages=[],
                markdown_files=[],
                confidence=0.0,
                processing_time=0,
                output_dir="",
                error="PyMuPDFê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install PyMuPDFë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
            )
        
        start_time = time.time()
        thread_id = threading.current_thread().ident
        
        print(f"\nğŸ“„ ìŠ¤ë ˆë“œ {thread_id}: PDF ë¶„ì„ ì‹œì‘")
        
        try:
            pdf_path = Path(pdf_path).resolve()
            if not pdf_path.exists():
                raise FileNotFoundError(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
            
            if output_dir is None:
                output_dir = Path(f"./output_{pdf_path.stem}_{int(time.time())}")
            else:
                output_dir = Path(output_dir).resolve()
            
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # í˜ì´ì§€ë³„ ë¶„í•  ì²˜ë¦¬
            return self._analyze_by_pages(pdf_path, output_dir, progress_callback, start_time)
                
        except Exception as e:
            self.logger.error(f"ìŠ¤ë ˆë“œ {thread_id}: ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            return LayoutAnalysisResult(
                success=False,
                pages=[],
                markdown_files=[],
                confidence=0.0,
                processing_time=time.time() - start_time,
                output_dir=str(output_dir) if 'output_dir' in locals() else "",
                error=str(e)
            )
    
    def _analyze_by_pages(self, pdf_path: Path, output_dir: Path, 
                         progress_callback, start_time: float) -> LayoutAnalysisResult:
        """í˜ì´ì§€ë³„ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬ (ìŠ¤ë ˆë“œë³„ ë…ë¦½ ì‹¤í–‰)"""
        
        thread_id = threading.current_thread().ident
        print(f"ğŸ“Š ìŠ¤ë ˆë“œ {thread_id}: í˜ì´ì§€ë³„ ë¶„ì„ ì‹œì‘ - {pdf_path.name}")
        
        # ìŠ¤ë ˆë“œë³„ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë¡œë“œ
        pipeline = self._get_pipeline(progress_callback)
        
        # PDF ì—´ê¸°
        doc = fitz.open(str(pdf_path))
        total_pages = len(doc)
        print(f"ğŸ“‘ ìŠ¤ë ˆë“œ {thread_id}: ì´ í˜ì´ì§€ ìˆ˜ - {total_pages}")
        
        if progress_callback:
            progress_callback(0, total_pages, f"PDF ë¶„ì„ ì¤€ë¹„ ì¤‘... (ì´ {total_pages}í˜ì´ì§€)")
        
        all_pages = []
        markdown_files = []
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„± (ìŠ¤ë ˆë“œë³„ë¡œ ë…ë¦½)
        temp_dir = output_dir / f"temp_images_{thread_id}"
        temp_dir.mkdir(exist_ok=True)
        
        try:
            # ê° í˜ì´ì§€ë¥¼ ê°œë³„ ì²˜ë¦¬
            for page_num in range(total_pages):
                try:
                    page_start = time.time()
                    current_page = page_num + 1
                    
                    print(f"ğŸ“„ ìŠ¤ë ˆë“œ {thread_id}: í˜ì´ì§€ {current_page}/{total_pages} ì²˜ë¦¬ ì‹œì‘")
                    
                    if progress_callback:
                        progress_callback(page_num, total_pages, 
                                        f"í˜ì´ì§€ {current_page}/{total_pages} ì¶”ì¶œ ì¤‘...")
                    
                    # í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ì¶”ì¶œ (ê³ í•´ìƒë„)
                    page = doc[page_num]
                    matrix = fitz.Matrix(2, 2)  # 2ë°° í•´ìƒë„
                    pix = page.get_pixmap(matrix=matrix)
                    temp_img_path = temp_dir / f"page_{current_page:04d}.png"
                    pix.save(str(temp_img_path))
                    print(f"  ğŸ–¼ï¸ ìŠ¤ë ˆë“œ {thread_id}: ì´ë¯¸ì§€ ì¶”ì¶œ ì™„ë£Œ - {temp_img_path.name}")
                    
                    if progress_callback:
                        progress_callback(page_num, total_pages, 
                                        f"í˜ì´ì§€ {current_page}/{total_pages} ë ˆì´ì•„ì›ƒ ë¶„ì„ ì¤‘...")
                    
                    # ë‹¨ì¼ í˜ì´ì§€ ë¶„ì„ (ìŠ¤ë ˆë“œë³„ ë…ë¦½ ëª¨ë¸ ì‚¬ìš©)
                    print(f"  ğŸ” ìŠ¤ë ˆë“œ {thread_id}: ë ˆì´ì•„ì›ƒ ë¶„ì„ ì‹œì‘...")
                    result = pipeline.predict(input=str(temp_img_path))
                    print(f"  âœ… ìŠ¤ë ˆë“œ {thread_id}: ë ˆì´ì•„ì›ƒ ë¶„ì„ ì™„ë£Œ")
                    
                    if progress_callback:
                        progress_callback(page_num, total_pages, 
                                        f"í˜ì´ì§€ {current_page}/{total_pages} ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì¤‘...")
                    
                    # ê²°ê³¼ ì²˜ë¦¬ ë° ë§ˆí¬ë‹¤ìš´ ìƒì„±
                    md_path = self._process_page_result(result, current_page, output_dir)
                    if md_path:
                        markdown_files.append(str(md_path))
                        print(f"  ğŸ“ ìŠ¤ë ˆë“œ {thread_id}: ë§ˆí¬ë‹¤ìš´ ì €ì¥ - {md_path.name}")
                    
                    # í˜ì´ì§€ë³„ JSON ê²°ê³¼ ì €ì¥
                    json_path = output_dir / f"page_{current_page:04d}_result.json"
                    with open(json_path, 'w', encoding='utf-8') as f:
                        json.dump(result, f, ensure_ascii=False, indent=2, default=str)
                    
                    page_time = time.time() - page_start
                    
                    all_pages.append({
                        "page_number": current_page,
                        "markdown_file": str(md_path) if md_path else None,
                        "json_file": str(json_path),
                        "processing_time": page_time,
                        "thread_id": thread_id
                    })
                    
                    print(f"  â±ï¸ ìŠ¤ë ˆë“œ {thread_id}: í˜ì´ì§€ ì²˜ë¦¬ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {page_time:.2f}ì´ˆ)")
                    
                    if progress_callback:
                        progress_callback(current_page, total_pages, 
                                        f"í˜ì´ì§€ {current_page}/{total_pages} ì™„ë£Œ")
                    
                except Exception as e:
                    print(f"  âŒ ìŠ¤ë ˆë“œ {thread_id}: í˜ì´ì§€ {current_page} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    self.logger.warning(f"ìŠ¤ë ˆë“œ {thread_id}: í˜ì´ì§€ {current_page} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    all_pages.append({
                        "page_number": current_page,
                        "error": str(e),
                        "thread_id": thread_id
                    })
            
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
            shutil.rmtree(temp_dir, ignore_errors=True)
            
        finally:
            doc.close()
        
        total_time = time.time() - start_time
        print(f"\nâœ… ìŠ¤ë ˆë“œ {thread_id}: ì „ì²´ ë¶„ì„ ì™„ë£Œ!")
        print(f"   ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"   í˜ì´ì§€ë‹¹ í‰ê· : {total_time/total_pages:.2f}ì´ˆ")
        print(f"   ìƒì„±ëœ ë§ˆí¬ë‹¤ìš´ íŒŒì¼: {len(markdown_files)}ê°œ")
        print(f"   ìŠ¤ë ˆë“œ ë…ë¦½ì„±: í™•ë³´ë¨")
        
        return LayoutAnalysisResult(
            success=True,
            pages=all_pages,
            markdown_files=markdown_files,
            confidence=0.95,
            processing_time=total_time,
            output_dir=str(output_dir),
            metadata={
                "total_pages": total_pages,
                "method": "page_by_page_threaded",
                "thread_id": thread_id,
                "avg_page_time": total_time / total_pages if total_pages > 0 else 0,
                "concurrent_processing": True
            }
        )
    
    def _process_page_result(self, result, page_num: int, output_dir: Path) -> Optional[Path]:
        """ë‹¨ì¼ í˜ì´ì§€ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜ (ìŠ¤ë ˆë“œ ì•ˆì „)"""
        try:
            md_text = ""
            
            # ê²°ê³¼ì—ì„œ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì˜¤ì§ 'markdown_texts' ê°’ë§Œ ì €ì¥)
            if isinstance(result, list):
                for item in result:
                    if hasattr(item, 'markdown'):
                        md_info = getattr(item, 'markdown')
                        if isinstance(md_info, dict):
                            txt = md_info.get('markdown_texts') or md_info.get('markdown') or ''
                            md_text += str(txt or '') + "\n"
                        else:
                            md_text += str(md_info or '') + "\n"
                    elif isinstance(item, dict):
                        md_info = item.get('markdown')
                        if isinstance(md_info, dict):
                            txt = md_info.get('markdown_texts') or md_info.get('markdown') or ''
                            md_text += str(txt or '') + "\n"
                        elif 'text' in item:
                            md_text += str(item.get('text') or '') + "\n"
            elif hasattr(result, 'markdown'):
                md_info = getattr(result, 'markdown')
                if isinstance(md_info, dict):
                    md_text = str(md_info.get('markdown_texts') or md_info.get('markdown') or '')
                else:
                    md_text = str(md_info or '')
            elif isinstance(result, dict):
                md_info = result.get('markdown')
                if isinstance(md_info, dict):
                    md_text = str(md_info.get('markdown_texts') or md_info.get('markdown') or '')
                else:
                    md_text = ''
            else:
                md_text = ''
            
            if not md_text.strip():
                md_text = f"# Page {page_num}\n\n[No text content detected]"
            
            # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥ (ìŠ¤ë ˆë“œ ì•ˆì „)
            md_path = output_dir / f"page_{page_num:04d}.md"
            md_path.write_text(md_text, encoding='utf-8')
            
            return md_path
            
        except Exception as e:
            thread_id = threading.current_thread().ident
            self.logger.error(f"ìŠ¤ë ˆë“œ {thread_id}: í˜ì´ì§€ {page_num} ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            return None
    
    def get_thread_info(self) -> Dict[str, Any]:
        """í˜„ì¬ ìŠ¤ë ˆë“œì˜ ëª¨ë¸ ì •ë³´ ë°˜í™˜ (ë””ë²„ê¹…ìš©)"""
        thread_id = threading.current_thread().ident
        thread_name = threading.current_thread().name
        has_pipeline = hasattr(self._local, 'pipeline') and self._local.pipeline is not None
        
        return {
            "thread_id": thread_id,
            "thread_name": thread_name,
            "has_pipeline": has_pipeline,
            "total_models_loaded": self._model_load_count
        }


def test_concurrent_analysis():
    """ë™ì‹œì„± í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    import sys
    import threading
    import time
    
    def progress_callback(current, total, message):
        """ì§„í–‰ë¥  í‘œì‹œ ì½œë°±"""
        thread_id = threading.current_thread().ident
        if total > 0:
            percent = (current / total) * 100
            print(f"ìŠ¤ë ˆë“œ {thread_id}: [{percent:.1f}%] {message}")
    
    def analyze_worker(service, pdf_path, worker_id):
        """ì›Œì»¤ ìŠ¤ë ˆë“œ í•¨ìˆ˜"""
        print(f"\nğŸš€ ì›Œì»¤ {worker_id} ì‹œì‘")
        
        result = service.analyze_document(
            pdf_path,
            output_dir=f"./test_output_worker_{worker_id}_{int(time.time())}",
            progress_callback=progress_callback
        )
        
        if result.success:
            print(f"âœ… ì›Œì»¤ {worker_id} ì„±ê³µ!")
            print(f"   ì²˜ë¦¬ëœ í˜ì´ì§€: {len(result.pages)}")
            print(f"   ìƒì„±ëœ ë§ˆí¬ë‹¤ìš´: {len(result.markdown_files)}")
            print(f"   ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ")
            print(f"   ìŠ¤ë ˆë“œ ì •ë³´: {result.metadata.get('thread_id')}")
        else:
            print(f"âŒ ì›Œì»¤ {worker_id} ì‹¤íŒ¨: {result.error}")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    if len(sys.argv) > 1:
        pdf_path = sys.argv[1]
    else:
        pdf_path = input("PDF íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
    
    if not Path(pdf_path).exists():
        print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pdf_path}")
        return
    
    service = LayoutAnalysisServicePaged()
    
    # ë™ì‹œì— 2ê°œ ì›Œì»¤ ì‹¤í–‰
    print("ğŸ”„ ë™ì‹œì„± í…ŒìŠ¤íŠ¸: 2ê°œ ì›Œì»¤ ë™ì‹œ ì‹¤í–‰")
    
    threads = []
    for i in range(2):
        thread = threading.Thread(
            target=analyze_worker,
            args=(service, pdf_path, i+1),
            name=f"Worker-{i+1}"
        )
        threads.append(thread)
        thread.start()
        time.sleep(1)  # 1ì´ˆ ê°„ê²©ìœ¼ë¡œ ì‹œì‘
    
    # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
    for thread in threads:
        thread.join()
    
    print("\nğŸ¯ ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"ì´ ë¡œë“œëœ ëª¨ë¸ ìˆ˜: {service._model_load_count}")


if __name__ == "__main__":
    test_concurrent_analysis()