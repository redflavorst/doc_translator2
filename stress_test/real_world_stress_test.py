import concurrent.futures
import time
import random
import requests
import json
import psutil
import logging
from pathlib import Path
from datetime import datetime
from typing import List, Dict
from dataclasses import dataclass, asdict
from urllib.parse import urlparse
from collections import deque
import threading
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


@dataclass
class TestResult:
    """ê°œë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼"""
    user_id: int
    pdf_file: str
    pdf_pages: int
    pdf_size_mb: float
    start_time: float
    end_time: float
    total_duration: float
    ocr_duration: float
    translation_duration: float
    success: bool
    error: str = None
    workflow_id: str = None
    cpu_peak: float = 0
    memory_peak_mb: float = 0


class RealWorldStressTester:
    def __init__(self, pdf_folder: str, base_url: str = "http://localhost:8000"):
        self.pdf_folder = Path(pdf_folder)
        self.base_url = base_url.rstrip("/")
        self.test_users = []
        self.results: List[TestResult] = []
        self.fail_details: List[Dict] = []

        # ë¡œê¹… ì„¤ì • (ìµœìš°ì„  ì„¸íŒ…)
        log_filename = f"stress_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s [%(levelname)s] %(message)s',
            handlers=[
                logging.FileHandler(log_filename),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

        # PDF íŒŒì¼ ë¡œë“œëŠ” ë¡œê±° ì¤€ë¹„ ì´í›„ ìˆ˜í–‰
        self.pdf_files = self._load_pdf_files()

        # ì¿ í‚¤ ë„ë©”ì¸
        self._cookie_domain = urlparse(self.base_url).hostname

        # ëœë¤ ìœ ë‹ˆí¬ ë¶„ë°°ìš© í’€ê³¼ ë½
        self._pool_lock = threading.Lock()
        self._shuffled_pool: deque = deque()
        # ì„œë²„ ìµœëŒ€ ë™ì‹œ ì›Œí¬í”Œë¡œ ìƒí•œì„ ìºì‹œí•˜ê¸° ìœ„í•œ ê°’(ì˜µì…˜)
        self.server_max_concurrent: int | None = None

    def _load_pdf_files(self) -> List[Dict]:
        """PDF íŒŒì¼ ì •ë³´ ë¡œë“œ"""
        pdf_files = []

        for pdf_path in self.pdf_folder.glob("*.pdf"):
            try:
                import fitz  # PyMuPDF
                doc = fitz.open(str(pdf_path))
                pdf_info = {
                    'path': pdf_path,
                    'name': pdf_path.name,
                    'pages': len(doc),
                    'size_mb': pdf_path.stat().st_size / (1024 * 1024)
                }
                doc.close()
                pdf_files.append(pdf_info)
                self.logger.info(f"Loaded PDF: {pdf_info['name']} ({pdf_info['pages']} pages, {pdf_info['size_mb']:.2f} MB)")
            except Exception as e:
                self.logger.error(f"Failed to load {pdf_path}: {e}")

        # í¬ê¸°ë³„ë¡œ ì •ë ¬
        pdf_files.sort(key=lambda x: x['pages'])

        self.logger.info(f"Total PDFs loaded: {len(pdf_files)}")
        return pdf_files

    def _pick_random_unique(self) -> Dict:
        """ì¤‘ë³µì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ì…”í”Œëœ í’€ì—ì„œ í•˜ë‚˜ì”© êº¼ë‚´ê¸°"""
        with self._pool_lock:
            if not self._shuffled_pool:
                pool = list(self.pdf_files)
                random.shuffle(pool)
                self._shuffled_pool = deque(pool)
            return self._shuffled_pool.popleft()

    def setup_test_users(self, count: int):
        """í…ŒìŠ¤íŠ¸ìš© ì‚¬ìš©ì ìƒì„± ë° ë¡œê·¸ì¸"""
        self.logger.info(f"Setting up {count} test users...")

        for i in range(count):
            username = f"stress_user_{i:04d}"
            email = f"stress{i:04d}@test.com"
            password = "StressTest123!"

            # íšŒì›ê°€ì… ì‹œë„ (ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ: ì´ë¯¸ ì¡´ì¬ ê°€ëŠ¥)
            try:
                requests.post(
                    f"{self.base_url}/api/v1/auth/register",
                    json={
                        "username": username,
                        "email": email,
                        "password": password
                    },
                    timeout=10
                )
            except Exception:
                pass

            # ë¡œê·¸ì¸
            try:
                session = requests.Session()
                response = session.post(
                    f"{self.base_url}/api/v1/auth/login",
                    json={
                        "username": username,
                        "password": password
                    },
                    timeout=30
                )

                if response.status_code == 200:
                    session_token = response.cookies.get('session_token')
                    # ì„¸ì…˜ê³¼ ì„¸ì…˜ í† í°ì„ í•¨ê»˜ ë³´ê´€í•˜ì—¬ ì—…ë¡œë“œì—ë„ ë™ì¼ ì„¸ì…˜ ì‚¬ìš©
                    self.test_users.append({
                        'id': i,
                        'username': username,
                        'session_token': session_token,
                        'session': session
                    })
                    self.logger.info(f"User ready: {username}")
                else:
                    self.logger.error(f"Login failed for {username}: {response.status_code} {response.text}")
            except Exception as e:
                self.logger.error(f"Failed to setup user {username}: {e}")

    def process_single_document(self, user_info: Dict, pdf_info: Dict) -> TestResult:
        """ë‹¨ì¼ ë¬¸ì„œ ì²˜ë¦¬ (ì „ì²´ íŒŒì´í”„ë¼ì¸)"""
        start_time = time.time()
        # ë¡œê·¸ì¸ì— ì‚¬ìš©í•œ ë™ì¼í•œ ì„¸ì…˜ì„ ìš°ì„  ì‚¬ìš©
        session = user_info.get('session') or requests.Session()
        # ì„¸ì…˜ í† í°ì´ ìˆê³  ìƒˆ ì„¸ì…˜ì¸ ê²½ìš° ì¿ í‚¤/í—¤ë”ë¥¼ ë³´ê°•
        if user_info.get('session_token') and 'session' not in user_info:
            token = user_info['session_token']
            try:
                session.cookies.set('session_token', token, domain=self._cookie_domain)
            except Exception:
                session.cookies.set('session_token', token)
            # í—¤ë”ì—ë„ ì§ì ‘ ì¶”ê°€(ë³´ìˆ˜ì  ì²˜ë¦¬)
            session.headers['Cookie'] = f"session_token={token}"

        # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (í´ë¼ì´ì–¸íŠ¸ í”„ë¡œì„¸ìŠ¤ ê¸°ì¤€)
        process = psutil.Process()
        cpu_peak = 0
        memory_peak_mb = 0

        try:
            # 1. PDF ì—…ë¡œë“œ
            self.logger.info(f"User {user_info['id']}: Uploading {pdf_info['name']}")

            # ì—…ë¡œë“œ ìš”ì²­ with ì¬ì‹œë„(í˜¼ì¡ ì‹œ 429 ì²˜ë¦¬)
            def _do_upload() -> requests.Response:
                with open(pdf_info['path'], 'rb') as f:
                    files = {'file': (pdf_info['name'], f, 'application/pdf')}
                    return session.post(
                        f"{self.base_url}/api/v1/documents/upload",
                        files=files,
                        timeout=120
                    )

            # 429 ì‹œ: ìŠ¬ë¡¯ì´ ë¹Œ ë•Œê¹Œì§€ ë°ë“œë¼ì¸ê¹Œì§€ ëŒ€ê¸°
            start_upload_wait = time.time()
            upload_deadline = start_upload_wait + getattr(self, 'upload_wait_seconds', 600)
            attempt = 0
            backoff = 1.0
            while True:
                upload_response = _do_upload()
                if upload_response.status_code == 429:
                    attempt += 1
                    now = time.time()
                    if now >= upload_deadline:
                        break
                    retry_after = upload_response.headers.get('Retry-After')
                    if retry_after:
                        try:
                            sleep_s = float(retry_after)
                        except Exception:
                            sleep_s = backoff + random.uniform(0, 0.5)
                    else:
                        sleep_s = backoff + random.uniform(0, 0.5)
                    # ë°ë“œë¼ì¸ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ìŠ¬ë¦½ ìº¡
                    if now + sleep_s > upload_deadline:
                        sleep_s = max(0.2, upload_deadline - now)
                    self.logger.warning(f"User {user_info['id']}: Server busy (429). waiting {sleep_s:.1f}s until slot free (attempt {attempt})")
                    time.sleep(sleep_s)
                    backoff = min(backoff * 2, 8.0)
                    continue
                break

            if upload_response.status_code != 200:
                raise Exception(f"Upload failed: {upload_response.status_code} {upload_response.text}")

            data = upload_response.json()
            workflow_id = data.get('workflow_id')
            if not workflow_id:
                raise Exception("workflow_id missing in upload response")

            upload_time = time.time()

            # 2. ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
            self.logger.info(f"User {user_info['id']}: Processing workflow {workflow_id}")

            ocr_complete = False
            ocr_duration = 0.0
            translation_duration = 0.0
            check_interval = 2.0
            last_logged_progress = -1

            # ë‹¨ê³„ë³„ íƒ€ì„ì•„ì›ƒ êµ¬ì„±
            ocr_max_wait = getattr(self, 'ocr_max_wait_seconds', 900)
            translation_max_wait = getattr(self, 'translation_max_wait_seconds', 900)
            ocr_deadline = upload_time + ocr_max_wait
            translation_start_time = None

            last_status_snapshot = None
            while True:
                # ë¦¬ì†ŒìŠ¤ ì²´í¬ (ì§§ì€ ì¸í„°ë²Œë¡œ ìƒ˜í”Œë§ ì •í™•ë„ í™•ë³´)
                cpu_current = process.cpu_percent(interval=0.05)
                memory_current = process.memory_info().rss / (1024 * 1024)
                cpu_peak = max(cpu_peak, cpu_current)
                memory_peak_mb = max(memory_peak_mb, memory_current)

                # ìƒíƒœ í™•ì¸
                try:
                    status_response = session.get(
                        f"{self.base_url}/api/v1/workflows/{workflow_id}",
                        timeout=30
                    )
                except requests.exceptions.ReadTimeout:
                    # ì¼ì‹œì  ì§€ì—°ì€ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬í•˜ì§€ ì•Šê³  ë‹¤ìŒ í´ë§ìœ¼ë¡œ
                    time.sleep(1.0)
                    continue

                if status_response.status_code == 200:
                    status_data = status_response.json()
                    last_status_snapshot = status_data
                    current_stage = status_data.get('current_stage')
                    status = status_data.get('status')
                    progress = status_data.get('progress_percentage', 0) or 0

                    # OCR ì™„ë£Œ ì‹œì  ê¸°ë¡
                    if not ocr_complete and current_stage in ['TRANSLATION', 'COMPLETION']:
                        ocr_complete = True
                        ocr_duration = time.time() - upload_time
                        translation_start_time = time.time()
                        self.logger.info(f"User {user_info['id']}: OCR completed in {ocr_duration:.2f}s")

                    # ì™„ë£Œ í™•ì¸
                    if status == 'COMPLETED':
                        # ë²ˆì—­ ì‹œì‘ ì‹œê°„ì´ ê¸°ë¡ë˜ì—ˆë‹¤ë©´ ê·¸ê²ƒì„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
                        if translation_start_time:
                            translation_duration = time.time() - translation_start_time
                        else:
                            translation_duration = time.time() - upload_time - ocr_duration
                        self.logger.info(f"User {user_info['id']}: Translation completed in {translation_duration:.2f}s")
                        break
                    elif status == 'FAILED':
                        raise Exception(f"Workflow failed: {status_data.get('error_info')}")

                    # ì§„í–‰ë¥  ë¡œê·¸ (10% ë‹¨ìœ„, ë³€í™” ì‹œì—ë§Œ)
                    if isinstance(progress, int):
                        bucket = (progress // 10) * 10
                        if bucket != last_logged_progress:
                            last_logged_progress = bucket
                            self.logger.debug(f"User {user_info['id']}: {bucket}% complete")

                # ë‹¨ê³„ë³„ íƒ€ì„ì•„ì›ƒ ê²€ì‚¬
                now_time = time.time()
                if not ocr_complete and now_time > ocr_deadline:
                    raise Exception("Timeout(OCR) waiting for completion")
                if ocr_complete:
                    # ë²ˆì—­ íƒ€ì„ì•„ì›ƒì€ ë²ˆì—­ ë‹¨ê³„ ì§„ì… ì‹œì ë¶€í„° ê³„ì‚°
                    trans_start = translation_start_time or now_time
                    if now_time > trans_start + translation_max_wait:
                        raise Exception("Timeout(TRANSLATION) waiting for completion")

                # ì§€í„°ê°€ ìˆëŠ” ëŒ€ê¸° (ìŠ¤íŒŒì´í¬ ì™„í™”)
                sleep_s = check_interval + random.uniform(-0.3, 0.3)
                if sleep_s < 0.2:
                    sleep_s = 0.2
                time.sleep(sleep_s)

            # ì´ ë£¨í”„ëŠ” ì™„ë£Œ ë˜ëŠ” ì˜ˆì™¸ë¡œë§Œ íƒˆì¶œí•¨

            # 3. ì„±ê³µ
            total_duration = time.time() - start_time

            result = TestResult(
                user_id=user_info['id'],
                pdf_file=pdf_info['name'],
                pdf_pages=pdf_info['pages'],
                pdf_size_mb=pdf_info['size_mb'],
                start_time=start_time,
                end_time=time.time(),
                total_duration=total_duration,
                ocr_duration=ocr_duration,
                translation_duration=translation_duration,
                success=True,
                workflow_id=workflow_id,
                cpu_peak=cpu_peak,
                memory_peak_mb=memory_peak_mb
            )

            self.logger.info(
                f"User {user_info['id']}: SUCCESS - Total {total_duration:.2f}s (OCR: {ocr_duration:.2f}s, Translation: {translation_duration:.2f}s)"
            )
            return result

        except Exception as e:
            total_duration = time.time() - start_time
            self.logger.error(f"User {user_info['id']}: FAILED - {str(e)}")
            # ìƒíƒœ ì¡°íšŒ ì‹œë„ (ê°€ëŠ¥í•˜ë©´ ì›Œí¬í”Œë¡œ ìƒíƒœ ì¶”ê°€)
            try:
                if 'workflow_id' in locals():
                    status_response = session.get(f"{self.base_url}/api/v1/workflows/{workflow_id}", timeout=10)
                    if status_response.status_code == 200:
                        status_data = status_response.json()
                        self.fail_details.append({
                            'user_id': user_info['id'],
                            'pdf': pdf_info['name'],
                            'reason': str(e),
                            'workflow_id': workflow_id,
                            'last_status': status_data
                        })
            except Exception:
                pass

            return TestResult(
                user_id=user_info['id'],
                pdf_file=pdf_info['name'],
                pdf_pages=pdf_info['pages'],
                pdf_size_mb=pdf_info['size_mb'],
                start_time=start_time,
                end_time=time.time(),
                total_duration=total_duration,
                ocr_duration=0.0,
                translation_duration=0.0,
                success=False,
                error=str(e),
                cpu_peak=cpu_peak,
                memory_peak_mb=memory_peak_mb
            )

    def run_concurrent_test(
        self,
        concurrent_users: int,
        pdf_distribution: str = 'random',
        duration_seconds: int = None,
        total_requests: int = None,
        per_user_once: bool = False
    ) -> Dict:
        """ë™ì‹œ ì‚¬ìš©ì í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.logger.info("=" * 60)
        self.logger.info(f"Starting concurrent test: {concurrent_users} users")
        self.logger.info(f"PDF distribution: {pdf_distribution}")
        self.logger.info("=" * 60)

        # PDF ì„ íƒ ì „ëµ
        def select_pdf(index: int) -> Dict:
            if not self.pdf_files:
                raise RuntimeError("No PDF files loaded")
            n = len(self.pdf_files)
            if pdf_distribution == 'sequential':
                return self.pdf_files[index % n]
            elif pdf_distribution == 'random_unique':
                return self._pick_random_unique()
            elif pdf_distribution == 'weighted' and n >= 3:
                # ì‘ì€ íŒŒì¼ 70%, ì¤‘ê°„ 20%, í° íŒŒì¼ 10%
                rand = random.random()
                first = n // 3 or 1
                second = (2 * n) // 3 or (first + 1)
                if rand < 0.7:
                    return random.choice(self.pdf_files[:first])
                elif rand < 0.9:
                    return random.choice(self.pdf_files[first:second])
                else:
                    return random.choice(self.pdf_files[second:])
            else:  # random
                return random.choice(self.pdf_files)

        # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        initial_cpu = psutil.cpu_percent(interval=1)
        initial_memory = psutil.virtual_memory().percent

        start_time = time.time()
        with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures: List[concurrent.futures.Future] = []
            request_count = 0
            used_user_ids = set()
            exhausted_users = False

            def _prune_done():
                # ì™„ë£Œëœ future ì œê±°í•˜ì—¬ í ê¸¸ì´ ìœ ì§€
                alive = []
                for f in futures:
                    if f.done():
                        try:
                            res = f.result(timeout=0)
                            self.results.append(res)
                        except Exception as err:
                            self.logger.error(f"Task failed with exception: {err}")
                    else:
                        alive.append(f)
                futures[:] = alive

            # ìš”ì²­ ìƒì„±
            if duration_seconds:
                # ì‹œê°„ ê¸°ë°˜
                while time.time() - start_time < duration_seconds:
                    for _ in range(concurrent_users):
                        _prune_done()
                        if len(futures) < concurrent_users * 2:  # í ì œí•œ
                            if per_user_once:
                                # ì•„ì§ ì œì¶œí•˜ì§€ ì•Šì€ ì‚¬ìš©ì ì„ íƒ
                                user = None
                                for candidate in self.test_users:
                                    if candidate['id'] not in used_user_ids:
                                        user = candidate
                                        break
                                if user is None:
                                    exhausted_users = True
                                    break
                                used_user_ids.add(user['id'])
                            else:
                                user = self.test_users[request_count % len(self.test_users)]
                            pdf = select_pdf(request_count)
                            future = executor.submit(self.process_single_document, user, pdf)
                            futures.append(future)
                            request_count += 1
                    # ë¨í”„ì—… + ì§€í„°
                    time.sleep(0.5 + random.uniform(-0.1, 0.1))
                    if exhausted_users and not futures:
                        break
            else:
                # íšŸìˆ˜ ê¸°ë°˜
                total_requests = total_requests or concurrent_users
                max_reqs = total_requests
                if per_user_once:
                    max_reqs = min(total_requests, len(self.test_users))
                for i in range(max_reqs):
                    _prune_done()
                    if per_user_once:
                        user = self.test_users[i]
                        used_user_ids.add(user['id'])
                    else:
                        user = self.test_users[i % len(self.test_users)]
                    pdf = select_pdf(i)
                    future = executor.submit(self.process_single_document, user, pdf)
                    futures.append(future)

                    # ë™ì‹œ ì‹¤í–‰ ì œí•œ
                    if (i + 1) % concurrent_users == 0:
                        time.sleep(1)

            # ë‚¨ì€ ê²°ê³¼ ìˆ˜ì§‘
            for future in concurrent.futures.as_completed(futures, timeout=None):
                try:
                    # ì‚¬ìš©ìë³„ í•©ì‚° íƒ€ì„ì•„ì›ƒ: ì—…ë¡œë“œ ëŒ€ê¸° + OCR + ë²ˆì—­ + ì—¬ìœ 
                    per_task_timeout = (
                        getattr(self, 'upload_wait_seconds', 600)
                        + getattr(self, 'ocr_max_wait_seconds', 900)
                        + getattr(self, 'translation_max_wait_seconds', 900)
                        + 120
                    )
                    result = future.result(timeout=per_task_timeout)
                    self.results.append(result)
                except Exception as e:
                    self.logger.error(f"Task failed with exception: {e}")

        # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ìµœì¢…
        final_cpu = psutil.cpu_percent(interval=1)
        final_memory = psutil.virtual_memory().percent

        # ê²°ê³¼ ë¶„ì„
        analysis = self.analyze_results()
        analysis['system_impact'] = {
            'cpu_increase': final_cpu - initial_cpu,
            'memory_increase': final_memory - initial_memory,
            'peak_cpu': max((r.cpu_peak for r in self.results), default=0),
            'peak_memory_mb': max((r.memory_peak_mb for r in self.results), default=0)
        }

        return analysis

    def analyze_results(self) -> Dict:
        """ê²°ê³¼ ë¶„ì„"""
        if not self.results:
            return {}

        successful = [r for r in self.results if r.success]
        failed = [r for r in self.results if not r.success]

        # ê¸°ë³¸ í†µê³„
        stats = {
            'total_requests': len(self.results),
            'successful': len(successful),
            'failed': len(failed),
            'success_rate': (len(successful) / len(self.results) * 100) if self.results else 0
        }

        if successful:
            # ì‹œê°„ í†µê³„
            total_times = [r.total_duration for r in successful]
            ocr_times = [r.ocr_duration for r in successful if r.ocr_duration > 0]
            trans_times = [r.translation_duration for r in successful if r.translation_duration > 0]

            total_sorted = sorted(total_times)
            n = len(total_sorted)
            stats['time_stats'] = {
                'total': {
                    'mean': sum(total_times) / n,
                    'min': total_sorted[0],
                    'max': total_sorted[-1],
                    'p50': total_sorted[n // 2],
                    'p90': total_sorted[int(n * 0.9) if n > 0 else 0],
                    'p99': total_sorted[int(n * 0.99)] if n > 100 else total_sorted[-1]
                }
            }

            if ocr_times:
                stats['time_stats']['ocr'] = {
                    'mean': sum(ocr_times) / len(ocr_times),
                    'min': min(ocr_times),
                    'max': max(ocr_times)
                }

            if trans_times:
                stats['time_stats']['translation'] = {
                    'mean': sum(trans_times) / len(trans_times),
                    'min': min(trans_times),
                    'max': max(trans_times)
                }

            # í˜ì´ì§€ë³„ ì„±ëŠ¥
            pages_groups: Dict[str, List[float]] = {}
            for r in successful:
                if r.pdf_pages <= 5:
                    group = 'small'
                elif r.pdf_pages <= 20:
                    group = 'medium'
                else:
                    group = 'large'
                pages_groups.setdefault(group, []).append(r.total_duration)

            stats['performance_by_size'] = {
                group: {
                    'count': len(times),
                    'avg_time': sum(times) / len(times)
                }
                for group, times in pages_groups.items()
            }

        # ì—ëŸ¬ ë¶„ì„
        if failed:
            error_types: Dict[str, int] = {}
            for r in failed:
                error_msg = (r.error or 'Unknown')
                error_msg = error_msg[:50]
                error_types[error_msg] = error_types.get(error_msg, 0) + 1
            stats['errors'] = error_types

        return stats

    def generate_report(self):
        """ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not self.results:
            self.logger.warning("No results to report")
            return

        # DataFrame ìƒì„±
        df = pd.DataFrame([asdict(r) for r in self.results])

        # ì‹œê°í™”
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))

        # 1. ì„±ê³µ/ì‹¤íŒ¨ ë¹„ìœ¨
        success_counts = df['success'].value_counts()
        labels = ['Failed', 'Success'] if False in success_counts.index else ['Success']
        values = [success_counts.get(False, 0), success_counts.get(True, 0)]
        axes[0, 0].pie(values, labels=labels, autopct='%1.1f%%', colors=['red', 'green'])
        axes[0, 0].set_title('Success Rate')

        # 2. ì²˜ë¦¬ ì‹œê°„ ë¶„í¬
        success_mask = df['success'] == True
        if success_mask.any():
            axes[0, 1].hist(df.loc[success_mask, 'total_duration'], bins=20, color='blue', alpha=0.7)
            axes[0, 1].set_xlabel('Total Duration (seconds)')
            axes[0, 1].set_ylabel('Count')
            axes[0, 1].set_title('Processing Time Distribution')

        # 3. OCR vs Translation ì‹œê°„
        if 'ocr_duration' in df.columns and (df['ocr_duration'] > 0).any():
            ocr_avg = df.loc[df['ocr_duration'] > 0, 'ocr_duration'].mean()
            trans_avg = df.loc[df['translation_duration'] > 0, 'translation_duration'].mean()
            axes[0, 2].bar(['OCR', 'Translation'], [ocr_avg, trans_avg], color=['orange', 'purple'])
            axes[0, 2].set_ylabel('Average Time (seconds)')
            axes[0, 2].set_title('OCR vs Translation Time')

        # 4. í˜ì´ì§€ ìˆ˜ë³„ ì²˜ë¦¬ ì‹œê°„
        if success_mask.any():
            axes[1, 0].scatter(df.loc[success_mask, 'pdf_pages'], df.loc[success_mask, 'total_duration'], alpha=0.5)
            axes[1, 0].set_xlabel('PDF Pages')
            axes[1, 0].set_ylabel('Total Duration (seconds)')
            axes[1, 0].set_title('Processing Time by PDF Size')

        # 5. ì‹œê°„ëŒ€ë³„ ì„±ê³µë¥ 
        df['hour'] = pd.to_datetime(df['start_time'], unit='s').dt.hour
        hourly_success = df.groupby('hour')['success'].mean() * 100
        if not hourly_success.empty:
            axes[1, 1].plot(hourly_success.index, hourly_success.values, marker='o')
            axes[1, 1].set_xlabel('Hour')
            axes[1, 1].set_ylabel('Success Rate (%)')
            axes[1, 1].set_title('Success Rate by Hour')

        # 6. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
        if (df['memory_peak_mb'] > 0).any() or (df['cpu_peak'] > 0).any():
            axes[1, 2].boxplot([
                df['cpu_peak'].dropna(),
                (df['memory_peak_mb'].dropna() / 100)
            ], tick_labels=['CPU (%)', 'Memory (GB/100)'])
            axes[1, 2].set_title('Resource Usage')

        plt.tight_layout()

        # íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        plt.savefig(f'stress_test_report_{timestamp}.png', dpi=100, bbox_inches='tight')
        df.to_csv(f'stress_test_results_{timestamp}.csv', index=False)

        # ì‹¤íŒ¨ ìƒì„¸ ì €ì¥
        if self.fail_details:
            import csv
            with open(f'stress_test_failures_{timestamp}.csv', 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['user_id', 'pdf', 'reason', 'workflow_id', 'status', 'stage', 'progress'])
                for item in self.fail_details:
                    status = item.get('last_status') or {}
                    writer.writerow([
                        item.get('user_id'),
                        item.get('pdf'),
                        item.get('reason'),
                        item.get('workflow_id'),
                        status.get('status'),
                        status.get('current_stage'),
                        status.get('progress_percentage')
                    ])

        # í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸
        with open(f'stress_test_summary_{timestamp}.txt', 'w', encoding='utf-8') as f:
            f.write("="*60 + "\n")
            f.write("STRESS TEST SUMMARY REPORT\n")
            f.write("="*60 + "\n\n")

            analysis = self.analyze_results()
            f.write(json.dumps(analysis, indent=2, ensure_ascii=False))

            f.write("\n\n" + "="*60 + "\n")
            f.write("RECOMMENDATIONS\n")
            f.write("="*60 + "\n")

            # ê¶Œì¥ì‚¬í•­
            success_rate = analysis.get('success_rate', 0)
            if success_rate >= 95:
                f.write("âœ… ì‹œìŠ¤í…œì´ ì•ˆì •ì ì…ë‹ˆë‹¤.\n")
            elif success_rate >= 80:
                f.write("âš ï¸ ì¼ë¶€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.\n")
            else:
                f.write("âŒ ì‹¬ê°í•œ ì„±ëŠ¥ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.\n")

            if 'time_stats' in analysis:
                avg_time = analysis['time_stats']['total']['mean']
                if avg_time > 300:  # 5ë¶„ ì´ìƒ
                    f.write("- ì²˜ë¦¬ ì‹œê°„ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n")
                if analysis['time_stats']['total']['p90'] > avg_time * 2:
                    f.write("- ì²˜ë¦¬ ì‹œê°„ í¸ì°¨ê°€ í½ë‹ˆë‹¤. ì¼ê´€ì„± ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.\n")

        plt.show()
        self.logger.info(f"Report saved: stress_test_report_{timestamp}.png")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='Real World Stress Test for Document Translation')
    parser.add_argument('pdf_folder', help='Folder containing PDF files')
    parser.add_argument('--users', type=int, default=10, help='Number of concurrent users')
    parser.add_argument('--duration', type=int, help='Test duration in seconds')
    parser.add_argument('--requests', type=int, help='Total number of requests')
    parser.add_argument('--distribution', choices=['random', 'sequential', 'weighted', 'random_unique'],
                        default='random', help='PDF selection strategy')
    parser.add_argument('--server', default='http://localhost:8000', help='Server URL')
    parser.add_argument('--per-user-once', action='store_true', help='Each user uploads at most once')
    parser.add_argument('--upload-wait-seconds', type=int, default=600, help='Max seconds to wait for an upload slot when server is busy (429)')
    parser.add_argument('--ocr-max-wait-seconds', type=int, default=900, help='Max seconds to wait for OCR stage per workflow')
    parser.add_argument('--translation-max-wait-seconds', type=int, default=900, help='Max seconds to wait for TRANSLATION stage per workflow')
    parser.add_argument('--prewarm', action='store_true', help='Run a quick prewarm before main test')
    parser.add_argument('--prewarm-requests', type=int, default=1, help='Number of prewarm requests')
    parser.add_argument('--prewarm-users', type=int, default=1, help='Concurrent users for prewarm')
    parser.add_argument('--prewarm-distribution', choices=['random', 'sequential', 'weighted'],
                        default='sequential', help='PDF selection strategy for prewarm')

    args = parser.parse_args()

    # í…ŒìŠ¤í„° ì´ˆê¸°í™”
    tester = RealWorldStressTester(args.pdf_folder, args.server)
    tester.upload_wait_seconds = args.upload_wait_seconds
    tester.ocr_max_wait_seconds = args.ocr_max_wait_seconds
    tester.translation_max_wait_seconds = args.translation_max_wait_seconds

    if not tester.pdf_files:
        print("âŒ No PDF files found in the specified folder")
        raise SystemExit(1)

    # í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì ì„¤ì • (ì˜ˆì—´ í¬í•¨ ëŒ€ë¹„, ì¶©ë¶„íˆ ìƒì„±)
    total_user_pool = max(args.users, args.prewarm_users) * 2
    tester.setup_test_users(total_user_pool)

    # ì˜ˆì—´ ì‹¤í–‰ (ì˜µì…˜)
    if args.prewarm:
        print(f"\nğŸ”¥ Prewarming with {args.prewarm_users} user(s), {args.prewarm_requests} request(s)")
        tester.run_concurrent_test(
            concurrent_users=args.prewarm_users,
            pdf_distribution=args.prewarm_distribution,
            duration_seconds=None,
            total_requests=args.prewarm_requests,
            per_user_once=True
        )
        # ê°„ë‹¨í•œ ì¿¨ë‹¤ìš´
        time.sleep(1)

    # ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print(f"\nğŸš€ Starting stress test with {args.users} concurrent users")
    print(f"ğŸ“ Using {len(tester.pdf_files)} PDF files")

    results = tester.run_concurrent_test(
        concurrent_users=args.users,
        pdf_distribution=args.distribution,
        duration_seconds=args.duration,
        total_requests=args.requests,
        per_user_once=args.per_user_once
    )

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("TEST RESULTS")
    print("="*60)
    print(json.dumps(results, indent=2, ensure_ascii=False))

    # ë¦¬í¬íŠ¸ ìƒì„±
    tester.generate_report()

    print("\nâœ… Test completed successfully!")


